{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a846b5-8ead-4ad8-b291-00c09a09ab0a",
   "metadata": {},
   "source": [
    "## Perform single-cell pycytominer pipelines\n",
    "\n",
    "Following single-cell curation with cytotable, we create single-cell profiles by applying the following steps:\n",
    "\n",
    "1. annotation\n",
    "2. normalization\n",
    "3. feature_selection\n",
    "\n",
    "Additionally, we create bulk profiles following feature selection.\n",
    "We call this \"Cameron's Method\".\n",
    "\n",
    "4. Aggregate (to form bulk, after single-cell processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b02e669-6b8b-49d7-a0a0-678eff76a854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maggiekeating/miniconda3/envs/IC_bench_4.2.6/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Modified Jenna's nf1_ic.ipynb file from the Cellpainting repo\n",
    "# https://github.com/WayScience/nf1_cellpainting_data/blob/main/3.processing_features/2.pycytominer_singlecell_pipelines.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pprint\n",
    "from pycytominer import aggregate, annotate, normalize, feature_select\n",
    "from pycytominer.cyto_utils import load_profiles, output, infer_cp_features\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609183fc-b780-4731-9a63-cbfb448d4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "feature_select_ops = [\n",
    "    \"variance_threshold\",\n",
    "    \"correlation_threshold\",\n",
    "    \"blocklist\",\n",
    "]\n",
    "\n",
    "# Columns to remove prior to single-cell aggregation via cameron's method\n",
    "cameron_unwanted_aggregate_cols = {\"Object\", \"Parent\", \"Site\", \"Image\"}\n",
    "\n",
    "# Set paths\n",
    "output_dir = pathlib.Path(\"../outputs/single_cell_profiles\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "metadata_dir = pathlib.Path(\"../../1.run_multi_IC_pipelines/data/Metadata/platemap_NF1_plate3_sub.csv\")\n",
    "\n",
    "# load in plate information\n",
    "dictionary_path = pathlib.Path(\"../outputs/plate_info_dictionary.yaml\")\n",
    "with open(dictionary_path) as file:\n",
    "    plate_info_dictionary = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88811904-baa5-47a4-846b-d733daef1952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'pipeline_1_IC': {   'dest_path': '../outputs/converted_data/pipeline_1_IC.parquet',\n",
      "                         'platemap_path': '../../1.run_multi_IC_pipelines/data/Metadata/platemap_NF1_plate3_sub.csv',\n",
      "                         'source_path': '../../2.cellprofiler_analysis/outputs/SQLites/pipeline_1_IC.sqlite'},\n",
      "    'pipeline_2_IC': {   'dest_path': '../outputs/converted_data/pipeline_2_IC.parquet',\n",
      "                         'platemap_path': '../../1.run_multi_IC_pipelines/data/Metadata/platemap_NF1_plate3_sub.csv',\n",
      "                         'source_path': '../../2.cellprofiler_analysis/outputs/SQLites/pipeline_2_IC.sqlite'}}\n"
     ]
    }
   ],
   "source": [
    "# add path to platemaps for each plate \n",
    "for plate in plate_info_dictionary.keys():\n",
    "    plate_info_dictionary[plate][\"platemap_path\"] = str(pathlib.Path(metadata_dir))\n",
    "\n",
    "\n",
    "# view the dictionary to assess that all info is added correctly\n",
    "pprint.pprint(plate_info_dictionary, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817b380-8fd5-464e-84d9-29505ae7fd41",
   "metadata": {},
   "source": [
    "## Perform single-cell pycytominer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc03cbc9-3c0d-4251-a66c-a82a2f10c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now performing single-cell pycytominer pipeline for pipeline_1_IC\n",
      "(2, 1028)\n",
      "Now performing single-cell pycytominer pipeline for pipeline_2_IC\n",
      "(2, 1014)\n"
     ]
    }
   ],
   "source": [
    "for plate, info in plate_info_dictionary.items():\n",
    "    print(f\"Now performing single-cell pycytominer pipeline for {plate}\")\n",
    "    output_annotated_file = str(pathlib.Path(f\"{output_dir}/{plate}_sc_annotated.parquet\"))\n",
    "    output_normalized_file = str(pathlib.Path(f\"{output_dir}/{plate}_sc_normalized.parquet\"))\n",
    "    output_feature_select_file = str(pathlib.Path(f\"{output_dir}/{plate}_sc_feature_selected.parquet\"))\n",
    "    output_aggregated_file = str(pathlib.Path(f\"{output_dir}/{plate}_bulk_camerons_method.parquet\"))\n",
    "\n",
    "    # Load single-cell profiles\n",
    "    single_cell_df = pd.read_parquet(info[\"dest_path\"])\n",
    "    \n",
    "    # Load platemap\n",
    "    platemap_df = pd.read_csv(info[\"platemap_path\"])\n",
    "    \n",
    "    # Step 1: Annotation\n",
    "    # add metadata from platemap file to extracted single cell features\n",
    "    annotated_df = annotate(\n",
    "        profiles=single_cell_df,\n",
    "        platemap=platemap_df,\n",
    "        join_on=[\"Metadata_well_position\", \"Image_Metadata_Well\"],\n",
    "    )\n",
    "\n",
    "    # rename site column to avoid any issues with identifying the column as metadata over feature\n",
    "    annotated_df = annotated_df.rename(columns={\"Image_Metadata_Site\": \"Metadata_Site\"})\n",
    "\n",
    "    # move metadata well, single cell count, and site to the front of the df (for easy visualization in python)\n",
    "    well_column = annotated_df.pop(\"Metadata_Well\")\n",
    "    singlecell_column = annotated_df.pop(\"Metadata_number_of_singlecells\")\n",
    "    site_column = annotated_df.pop(\"Metadata_Site\")    \n",
    "\n",
    "    # insert the columns in specific parts of the dataframe\n",
    "    annotated_df.insert(2, \"Metadata_Well\", well_column)\n",
    "    annotated_df.insert(3, \"Metadata_Site\", site_column)\n",
    "    annotated_df.insert(4, \"Metadata_number_of_singlecells\", singlecell_column)\n",
    "\n",
    "    # save annotated df as parquet file\n",
    "    output(\n",
    "        df=annotated_df,\n",
    "        output_filename=output_annotated_file,\n",
    "        output_type=\"parquet\",\n",
    "    )\n",
    "    \n",
    "    # Step 2: Normalization\n",
    "    normalized_df = normalize(\n",
    "        profiles=output_annotated_file,\n",
    "        method=\"standardize\",\n",
    "        output_file=output_normalized_file,\n",
    "        output_type=\"parquet\",\n",
    "    )\n",
    "    \n",
    "    # Step 3: Feature selection\n",
    "    feature_select(\n",
    "        output_normalized_file,\n",
    "        operation=feature_select_ops,\n",
    "        output_file=output_feature_select_file,\n",
    "        output_type=\"parquet\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Cameron's method of aggregation\n",
    "    feature_select_df = load_profiles(output_feature_select_file)\n",
    "    # Specify metadata columns in aggregation step to ensure they are retained for downstream analysis\n",
    "    metadata_cols = infer_cp_features(feature_select_df, metadata=True)\n",
    "    metadata_cols = [x for x in metadata_cols if all(col not in x for col in cameron_unwanted_aggregate_cols)]\n",
    "    \n",
    "    aggregate_df = aggregate(\n",
    "        population_df=feature_select_df,\n",
    "        operation=\"median\",\n",
    "        strata=metadata_cols,\n",
    "        output_file=output_aggregated_file,\n",
    "        output_type=\"parquet\"\n",
    "    )\n",
    "\n",
    "    print(aggregate_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
